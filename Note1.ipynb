{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the likelihood of a user clicking on an ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a Pandas dataframe with the sample data\n",
    "df = pd.DataFrame({\n",
    "    'age': [25, 35, 45, 28, 42, 33],\n",
    "    'income': [50000, 75000, 90000, 60000, 85000, 70000],\n",
    "    'gender': ['Male', 'Female', 'Male', 'Female', 'Male', 'Female'],\n",
    "    'interests': ['Sports', 'Music', 'Travel', 'Fashion', 'Sports', 'Travel'],\n",
    "    'clicked_on_ad': [True, False, False, True, False, True]\n",
    "})\n",
    "\n",
    "# Label encode the categorical variables\n",
    "encoder = LabelEncoder()\n",
    "df['gender'] = encoder.fit_transform(df['gender'])\n",
    "df['interests'] = encoder.fit_transform(df['interests'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.drop('clicked_on_ad', axis=1), df['clicked_on_ad'], test_size=0.2)\n",
    "\n",
    "# Build a logistic regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict the likelihood of a user clicking on an ad\n",
    "y_pred = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "accuracy = accuracy_score(y_test, y_pred.round())\n",
    "print('Accuracy:', accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-touch attribution model:\n",
      "source\n",
      "Facebook     0.1\n",
      "Google       0.1\n",
      "Instagram    0.1\n",
      "Twitter      0.2\n",
      "Name: conversion, dtype: float64\n",
      "\n",
      "Last-touch attribution model:\n",
      "source\n",
      "Facebook     0.1\n",
      "Google       0.1\n",
      "Instagram    0.1\n",
      "Twitter      0.2\n",
      "Name: conversion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load sample data into a Pandas dataframe\n",
    "df = pd.DataFrame({\n",
    "    'user_id': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'source': ['Facebook', 'Facebook', 'Google', 'Google', 'Google', 'Twitter', 'Twitter', 'Twitter', 'Instagram', 'Instagram'],\n",
    "    'conversion': [False, True, False, True, False, True, False, True, False, True]\n",
    "})\n",
    "\n",
    "# First-touch attribution model\n",
    "first_touch = df.drop_duplicates(subset=['user_id'], keep='first')\n",
    "first_touch_conversions = first_touch.groupby('source')['conversion'].sum()\n",
    "first_touch_conversion_rate = first_touch_conversions / len(first_touch)\n",
    "\n",
    "print('First-touch attribution model:')\n",
    "print(first_touch_conversion_rate)\n",
    "\n",
    "# Last-touch attribution model\n",
    "last_touch = df.drop_duplicates(subset=['user_id'], keep='last')\n",
    "last_touch_conversions = last_touch.groupby('source')['conversion'].sum()\n",
    "last_touch_conversion_rate = last_touch_conversions / len(last_touch)\n",
    "\n",
    "print('\\nLast-touch attribution model:')\n",
    "print(last_touch_conversion_rate)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incrementality-based Attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsfagundes/Library/Python/3.7/lib/python/site-packages/ipykernel_launcher.py:22: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (2) does not match length of index (5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/74/ctw0cxv57bv_0qt4034v71_c0000gn/T/ipykernel_1277/1850626107.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Compute the incremental conversions and revenue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob_control'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'treatment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob_treatment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreatment\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'treatment'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'incremental_conversions'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob_treatment'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'prob_control'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3610\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3611\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3612\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3614\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3782\u001b[0m         \u001b[0mensure\u001b[0m \u001b[0mhomogeneity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m         \"\"\"\n\u001b[0;32m-> 3784\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m         if (\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_list_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4509\u001b[0;31m             \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_length_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msanitize_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/pandas/core/common.py\u001b[0m in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         raise ValueError(\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;34m\"does not match length of index \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (2) does not match length of index (5)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the ad data as a Pandas DataFrame\n",
    "data = pd.DataFrame({\n",
    "    'treatment': [0, 0, 1, 1, 1],\n",
    "    'converted': [0, 0, 0, 1, 0],\n",
    "    'revenue': [0, 0, 0, 100, 0],\n",
    "    'cost': [50, 60, 70, 80, 75]\n",
    "})\n",
    "\n",
    "# Split data into treatment and control groups\n",
    "treatment = data[data['treatment'] == 1]\n",
    "control = data[data['treatment'] == 0]\n",
    "\n",
    "# Compute the conversion rates for treatment and control groups\n",
    "conversion_rate_treatment = treatment['converted'].mean()\n",
    "conversion_rate_control = control['converted'].mean()\n",
    "\n",
    "# Compute the incremental conversion rate and lift\n",
    "incremental_conversion_rate = conversion_rate_treatment - conversion_rate_control\n",
    "incremental_lift = incremental_conversion_rate / conversion_rate_control\n",
    "\n",
    "# Train a logistic regression model to estimate incremental conversion probability\n",
    "model = LogisticRegression(random_state=0).fit(data[['treatment']], data['converted'])\n",
    "\n",
    "# Compute the incremental conversions and revenue\n",
    "data['prob_control'] = model.predict_proba(control[['treatment']])[:, 1]\n",
    "data['prob_treatment'] = model.predict_proba(treatment[['treatment']])[:, 1]\n",
    "data['incremental_conversions'] = data['prob_treatment'] - data['prob_control']\n",
    "data['incremental_revenue'] = data['incremental_conversions'] * data['revenue']\n",
    "\n",
    "# Compute the incremental ROI\n",
    "incremental_profit = data['incremental_revenue'].sum() - treatment['cost'].sum()\n",
    "incremental_roi = incremental_profit / treatment['cost'].sum()\n",
    "\n",
    "print('Incremental conversion rate:', incremental_conversion_rate)\n",
    "print('Incremental lift:', incremental_lift)\n",
    "print('Incremental ROI:', incremental_roi)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
